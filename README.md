# Telecom X ‚Äì Predicci√≥n de Churn (Parte 2)

Proyecto completo de anal√≠tica y machine learning para estimar el riesgo de cancelaci√≥n (churn) en una telco LATAM. Incluye pipeline reproducible de **ingesti√≥n, limpieza, ingenier√≠a ligera, selecci√≥n de variables, modelado comparativo, evaluaci√≥n avanzada (ROC / PR / threshold tuning), interpretabilidad (importancias, SHAP / fallback), persistencia de artefactos y recomendaciones estrat√©gicas** contenido en el notebook `TelecomX2_LATAM.ipynb`.

---

## üßæ Resumen Ejecutivo

> (Sustituir los marcadores tras ejecutar el notebook)
>
> El mejor modelo final fue **`<BEST_MODEL>`** con **F1 = `<F1>`**, **Recall = `<RECALL>`** y **ROC-AUC = `<ROC>`** sobre el conjunto de test. Se adopt√≥ un umbral operativo = **`<THRESHOLD>`** optimizado para maximizar F1 (alternativa con Recall‚â•0.80 evaluada). Las variables con mayor impacto en la probabilidad de churn incluyen: `<TOP_FEATURES>`. Con estas se√±ales se prioriza la segmentaci√≥n proactiva de clientes de alto riesgo, optimizando campa√±as de retenci√≥n y reduciendo costos asociados a p√©rdida de ingresos recurrentes.
>
> Se recomienda monitorear mensualmente el desempe√±o del modelo (F1, Recall, drift en distribuci√≥n de probabilidades) y recalibrar el umbral ante cambios significativos.

Tabla r√°pida (ejemplo a completar):

| M√©trica            | Valor            |
| ------------------- | ---------------- |
| F1 Test             | `<F1>`         |
| Recall Test         | `<RECALL>`     |
| Precision Test      | `<PRECISION>`  |
| ROC-AUC Test        | `<ROC>`        |
| Threshold operativo | `<THRESHOLD>`  |
| Modelo              | `<BEST_MODEL>` |

---

---

## üìÇ Estructura del Repositorio

```
‚îú‚îÄ‚îÄ TelecomX2_LATAM.ipynb        # Notebook principal (pipeline end‚Äëto‚Äëend)
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ TelecomX_model_ready.parquet  # Dataset base (procesado parte 1)
‚îÇ   ‚îî‚îÄ‚îÄ telecomX_model_ready.csv      # Export generado al cargar
‚îú‚îÄ‚îÄ best_churn_model.joblib       # (Se genera tras ejecutar secci√≥n 4.4)
‚îî‚îÄ‚îÄ README.md
```

> El archivo `best_churn_model.joblib` se crea s√≥lo despu√©s de ejecutar la evaluaci√≥n extendida (4.4) y guardar artefactos.

---

## üß™ Objetivo

Construir y comparar modelos supervisados para predecir probabilidad de churn, priorizando **F1** y **Recall** (sensibles para retenci√≥n), generando adem√°s un umbral operativo y explicaciones de variables clave.

---

## üîç Flujo Metodol√≥gico (Resumen de Secciones)

| Secci√≥n       | Contenido                                                              | Notas                                         |
| -------------- | ---------------------------------------------------------------------- | --------------------------------------------- |
| 2.1            | Carga y exploraci√≥n inicial                                           | Detecci√≥n heur√≠stica de la columna objetivo |
| 2.2‚Äì2.3       | Limpieza, eliminaci√≥n de columnas irrelevantes, codificaci√≥n One-Hot | Manejo robusto de target heterog√©neo         |
| 2.4‚Äì2.6       | An√°lisis de desbalance, (opcional SMOTE), escalado                    | Escalado s√≥lo para modelos sensibles         |
| 3.1‚Äì3.2       | Correlaciones y selecci√≥n simple de features                          | Heur√≠stica top-N por                         |
| 4.1‚Äì4.3       | Split, entrenamiento y m√©tricas base                                  | Logistic, KNN, RandomForest, Linear SVC       |
| 4.4            | ROC, Precision-Recall, comparaci√≥n train/test, tuning de umbral       | Guarda artefactos + threshold                 |
| 4.5 (opcional) | Validaci√≥n cruzada + RandomizedSearch ligero                          | S√≥lo actualiza si mejora F1                  |
| 5.1            | Importancia/coeficientes de modelos                                    | Tabla unificada + gr√°ficos                   |
| 5.3 (opcional) | Interpretabilidad SHAP / fallback permutation importance               | Muestra reducida para velocidad               |
| 6              | Borrador automatizado de conclusiones estrat√©gicas                    | Plantilla editable                            |

---

## üßæ Datos

- Archivo base: `data/TelecomX_model_ready.parquet` (resultado de la parte 1).
- El notebook exporta a CSV (`telecomX_model_ready.csv`) para referencia externa.
- La columna objetivo se mapea de valores textuales/booleanos/num√©ricos a {0,1} con validaciones (umbral ‚â§5% de valores no mapeables).

---

## üõ†Ô∏è Dependencias Principales

| Grupo             | Librer√≠as                                      |
| ----------------- | ----------------------------------------------- |
| Core              | pandas, numpy, pyarrow                          |
| ML                | scikit-learn, imbalanced-learn (SMOTE opcional) |
| Visualizaci√≥n    | matplotlib, seaborn                             |
| Interpretabilidad | shap (opcional)                                 |
| Persistencia      | joblib                                          |

### Instalaci√≥n R√°pida (Windows PowerShell)

```powershell
python -m venv .venv
./.venv/Scripts/Activate.ps1
pip install --upgrade pip
pip install pandas numpy pyarrow scikit-learn imbalanced-learn seaborn matplotlib joblib shap
```

> Si no deseas SHAP inicialmente, puedes omitir `shap` (la celda 5.3 mostrar√° un mensaje y usar√° fallback si corresponde).

---

## ‚ñ∂Ô∏è Ejecuci√≥n del Notebook

1. Activa el entorno virtual y abre VS Code / Jupyter.
2. Ejecuta secuencialmente las celdas (secciones 2 ‚Üí 6).
3. Verifica que `metrics_df` y el modelo con mejor F1 se impriman en 4.3.
4. Ejecuta 4.4 para curvas, threshold y guardado `best_churn_model.joblib`.
5. (Opcional) Ejecuta 4.5 para tuning ligero.
6. Re-ejecuta 5.1 y (opcional) 5.3 si hubo tuning que cambie importancias.
7. Ejecuta 6.1 para generar el borrador de conclusiones y edita seg√∫n criterio de negocio.

### Carga del Modelo Guardado (Ejemplo)

```python
import joblib
art = joblib.load('best_churn_model.joblib')
model = art['model']
scaler = art['scaler']
features = art['features']
thr = art['threshold']
# Sup√≥n nuevo DataFrame df_new con mismas columnas originales antes de dummies
# -> Debes replicar pipeline de preparaci√≥n para crear X_encoded[features]
```

---

## üìä M√©tricas

Se construye una tabla comparativa con: `Accuracy`, `Precision`, `Recall`, `F1`, `ROC_AUC` (si hay probabilidades).
La **optimizaci√≥n de umbral** escanea valores 0.05‚Üí0.95 buscando m√°ximo F1 y alternativa con `Recall ‚â• 0.80`.

### Ejemplo de interpretaci√≥n

- Gap `F1_train - F1_test` > 0.05 ‚Üí alerta de posible overfitting.
- Si RandomForest domina, se reportan importancias; si Logistic, coeficientes (signo = direcci√≥n del efecto).

---

## üîç Interpretabilidad

- **Importancias**: RandomForest (`feature_importances_`), Logistic / LinearSVC (`coef_`).
- **SHAP (5.3)**: Usa `TreeExplainer` sobre muestra (‚â§400 filas) para impacto global; fallback a permutation importance si `shap` no est√°.

---

## üß™ Tuning (4.5)

RandomizedSearch con mallas discretas:

- RandomForest: profundidad, n_estimators, min_samples_split/leaf, max_features.
- LogisticRegression: C y solver.
  S√≥lo reemplaza el modelo en `models` y actualiza `metrics_df` si mejora F1 en test ‚â• 0.001.

---

## üíæ Persistencia y Deployment Inicial

`best_churn_model.joblib` contiene:

```python
{
  'model_name': <str>,
  'model': <estimador sklearn>,
  'features': <lista str>,
  'scaler': <StandardScaler or None>,
  'threshold': <float>,
  'metrics_table': metrics_df
}
```

Para un API / batch scoring futuro:

1. Replicar pipeline de limpieza + dummies.
2. Seleccionar las mismas `features` (rellenar faltantes con 0 si aparecen nuevas dummy columns).
3. Aplicar `scaler` si no es None.
4. Obtener `proba = model.predict_proba(X)[:,1]` y clasificar con `threshold` guardado.

---

## ‚úÖ Buenas Pr√°cticas Implementadas

- Validaciones tempranas de variables clave.
- Manejo de target heterog√©neo con tokens positivos/negativos.
- Control de desbalance (SMOTE condicional).
- Separaci√≥n l√≥gica de pasos y reproducibilidad de features.
- Threshold data-driven (F1 y alternativa recall alto).
- Guardado de artefactos y metadata para reproducibilidad.

---

## üöÄ Pr√≥ximos Pasos Recomendados

- Grid/Random/Bayesian Search m√°s profundo (recursos permitting).
- A√±adir **permutation importance** estable para todos los modelos.
- Implementar **validaci√≥n temporal** si hay componente temporal en el churn.
- Monitoreo de drift (PSI, KS) y reentrenos programados.
- Integrar m√©tricas de negocio: LTV, costo de retenci√≥n, priorizaci√≥n econ√≥mica.
- Despliegue como servicio REST / batch (FastAPI + contenedor).

---

## üîê Consideraciones

- Verificar compliance y privacidad si se a√±aden datos sensibles.
- Documentar versiones exactas (se recomienda `pip freeze > requirements.txt`).

Ejemplo r√°pido:

```powershell
pip freeze > requirements.txt
```

---

## üìÑ Licencia

(Agregar tipo de licencia aqu√≠, ej.: MIT, Apache 2.0).

---

## üë§ Autor

Proyecto desarrollado como parte del desaf√≠o "Challenge ONE Data Science ‚Äì Telecom X (Parte 2)".

---

## üÜò Soporte

Si encuentras un issue:

1. Crear un *Issue* con: descripci√≥n, paso para reproducir, traceback y secci√≥n del notebook.
2. Adjuntar versi√≥n de Python y scikit-learn (`python -c "import sklearn, sys; print(sys.version); print(sklearn.__version__)"`).

---

## ‚ú® Resumen Ejecutivo (plantilla)

> El mejor modelo fue `<MODEL>` con F1=`<F1>`. Principales impulsores: `<FEATURES>`. Umbral operativo = `<THR>`. Pr√≥ximos pasos: mejorar hiperpar√°metros, monitorear drift, evaluar impacto econ√≥mico.

---

## üîÅ Reproducibilidad R√°pida

1. Clonar repositorio.
2. Crear y activar entorno virtual.
3. `pip install -r requirements.txt`.
4. Abrir y ejecutar `TelecomX2_LATAM.ipynb` en orden.
5. Verificar creaci√≥n de `best_churn_model.joblib`.

### Script de extracci√≥n de m√©tricas (opcional)

```python
import joblib, pandas as pd
art = joblib.load('best_churn_model.joblib')
print('Modelo:', art['model_name'])
print('Threshold:', art['threshold'])
print(art['metrics_table'])
```

---

## üß™ Verificaci√≥n R√°pida del Entorno

```powershell
python -c "import sklearn, pandas, numpy; print('sklearn', sklearn.__version__)"
```

---

## üìå Checklist de Entrega Final

- [ ] Notebook ejecutado sin errores (celdas en orden)
- [ ] M√©tricas finales reemplazadas en Resumen Ejecutivo
- [ ] Archivo `best_churn_model.joblib` generado
- [ ] README actualizado (sin placeholders)
- [ ] `requirements.txt` congelado si se desea reproducibilidad exacta (`pip freeze > requirements.txt`)

---

## üóÇ Versionado y Congelaci√≥n (Opcional)

Para entornos productivos, fijar versiones exactas:

```powershell
pip freeze | Out-File -Encoding UTF8 requirements_exact.txt
```

---

---

¬°Listo! Tras reemplazar marcadores, el documento queda listo para presentaci√≥n / repositorio p√∫blico.
